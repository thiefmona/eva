# java

## redis

### 常用数据结构和应用场景

     string    缓存 计数器
     List      阻塞队列
     Hash      存储关系型数据表中记录
     Set       统计网站的独立ip
     Zset      带权重的队列 排行榜



### 缓存

- 穿透、击穿、雪崩

	- 穿透

	  查询一个不存在的数据 mysql查询不到数据也不会写入缓存 就会导致每次请求查询数据库
	  
		- 缓存空数据

		  查询返回的数据为空 仍然将这个空结果加入缓存
		  
		  优点 实现简单
		  缺点 消耗内存 可能会发生数据不一致的问题 (本来没有 后来数据库写入了)
		  
		- 布隆过滤器

		  优点 内存占用少 没有多余key
		  缺点 实现复杂 存在误判
		  
	- 击穿

	  给一个热点key设置了过期时间 当key过期的时候 恰好这个时间点正好有大量针对这个key的并发请求 可能瞬间压垮数据库
	  
		- 互斥锁

		  强一致 性能差
		  
		- 逻辑过期

		  高可用 性能好  高并发情况下不能保证数据绝对一致
		  
	- 雪崩

	  同一段时间大量key失效或者redis宕机 导致大量的请求到达数据库 导致数据库压力过大
	  
		- 给不同的key设置不同的过期时间

		- 利用Redis集群提高服务的高可用性

		- 给缓存业务添加降级策略

		- 给业务添加多级缓存

- redis和mysql数据一致性

  黑马 P05
  
	- 双写一致性

		- 延迟双删

		  延迟双删 如果是写操作 我们先把数据库中的数据删除 然后更新数据库 最后再延迟删除缓存中的数据 其中这个延迟多久不太好确定 再延迟的过程中可能会出现脏数据 并不能保证强一致性
		  
			- 允许延迟一致的业务

				- 采用异步通知

				  使用MQ中间件 更新数据后 通知缓存删除
				  利用canal中间件 不需要修改业务代码 伪装为mysql的一个从节点 canal通过读取binlog数据更新缓存
				  
			- 强一致性的业务

				- 采用Redisson提供的读写锁

				  共享锁 读锁readLock 加锁之后 其他线程可以共享读操作
				  排他锁 也叫独占锁writeLock 加锁之后 阻塞其他线程读写操作
				  
- 持久化

	- RDB

	  Redis DataBase Backup file(Redis数据备份文件) 也被叫做Redis数据快照 简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后 从磁盘读取文件 恢复数据
	  
	- AOF

	  Append Only File(追加文件) Redis处理的每一个写命令都会记录在AOF文件。可以看作是命令日志文件
	  
- 数据过期策略

  两种策略配合使用
  
	- 惰性删除

	  设置该key过期时间后 我们不去管他 当需要该key时 在检查key是否过期 如果过期 就删除他 反之 就返回该key
	  优点 对CPU友好 之会在使用该key时 才会进行过期检查 对于很多用不到的key不用浪费时间进行检查
	  缺点 对内存不友好 如果一个key已经过期 但是一直没有使用 那么该key就会一直存在内存中 内存永远不会释放
	  
	- 定期删除

	  每隔一段时间 对一些key进行检查 删除里面过期的key
	  优点 可以通过限制删除操作执行的时长和频率减少删除操作对cpu的影响 另外定期删除 可以有效释放过期键占用的内存
	  缺点 难以确定删除操作执行的时长和频率
	  slow模式 定时任务 可以修改rdis.config来调整频率
	  fast模式 执行频率不固定
	  
- 数据淘汰策略

  8种 重点后面三个
  
	- 默认 noeviction

	  不淘汰任何key 但是内存满了不允许写入新的数据
	  
	- LRU

	  Least Recently Used 最近最少使用
	  
	- LFU

	  Least Frequently Used 最少频率使用
	  
### 分布式锁

- setnx

	- Redis分布式锁如何合理的控制锁的有效时长

	  1 根据业务执行时间预估
	  2 给锁续期
	  
- redission

	- 看门狗

- 问题

	- redis分布式锁是如何实现的

	  先按照自己简历上的业务进行描述分布式锁的使用场景
	  我们使用的是基于redisson实现的分布式锁 底层是setnx命令和lua脚本(使用lua脚本用于保证原子性)
	  
	- redisson实现分布式锁如何合理的控制锁的有效时长

	  在redisson的分布式锁中 提供了一个watchDog看门狗机制 一个线程获取锁以后 wotchDog回归持有锁的线程续期 默认是10秒续期一次
	  
	- Redisson的分布式锁 是可以重入的吗

	  可以重入 多个锁重入需要判断是否是当前线程 在redis中进行存储的时候使用hash结构 来存储线程信息和重入次数
	  
	- Redisson锁能解决主从数据一致的问题吗

	  不能解决 但是可以使用Redisson提供的红锁来解决 但是这样的话 性能就太低了 如果业务中非要保证数据的强一致性 建议使用基于CP模型的zookeeper来实现分布式锁
	  
### 计数器

### 保存token

### 消息队列

### 延迟队列

### 集群

- 主从复制

	- 概念

	  单节点redis的并发能力是有上限的 要进一步提高redis的并发能力 就需要搭建主从集群 实现读写分离 一般都是一主多从 一般都是主节点负责写数据 从节点读数据
	  
	- 主从同步数据的流程

		- 全量同步

		  从节点请求主节点同步数据(replication id   offset)
		  主节点判断是否是第一次请求 是第一次就与从节点同步版本信息(replicaton id和offset)
		  主节点执行bgsave 生成rdb文件后 发送给从节点去执行
		  在rdb执行期间 主节点会以命令的方式记录到缓冲区(一个日志文件)
		  把生成之后的日志记录文件发送给从节点进行同步
		  
		- 增量同步

		  从节点请求主节点同步数据 主节点判断是不是第一次请求 不是第一次就获取从节点的offset值
		  主节点从命令日志文件中读取offset之后的值 发送给从节点进行数据同步
		  
- 哨兵模式

	- 作用

	  Redis提供了哨兵Sentinel机制来实现主从集群的自动故障恢复
	  监控 Sentinel会不断检查master和slave是否不断按预期工作
	  自动故障恢复 如果master故障 Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主
	  通知 Sentinel充当Redis客户端的服务发现来源 当集群发生故障转移时 会将最新消息推送给redis的客户端
	  
- 分片集群

  集群中多个master 每个master保存不同数据
  每个master都可以有多个slave节点
  master之间通过ping检测彼此健康状态
  客户端请求可以访问集群任意节点 最终都会转发到正确节点
  
	- redis分片集群中是数据是怎么存储和读取的

	  Redis分片集群引入哈希槽的概念 Redis集群有16384个哈希槽
	  将16384个哈希槽分配到不同的实例
	  读写数据 根据key的有效部分计算哈希值 对16384取余 余数作为插槽 寻找插槽所在的实例
	  
- 问题

	- 怎么保证Redis的高并发高可用

	  哨兵模式 实现主从集群的自动故障恢复(监控 自动故障恢复 通知)
	  
	- 你们使用Redis是单点还是集群，哪种集群

	  主从 一主一从 + 哨兵
	  
	- Reids集群脑裂怎么解决

	  有的时候由于网络等原因可能会出现脑裂的情况，就是说，由于redis master节点和redis salve节点和sentinel处于不同的网络分区，使得sentinel没 能够心跳感知到master，所以通过选举的方式提升了一个salve为master，这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在 old master那里写入数据，新节点无法同步数据，当网络恢复后，sentinel会 
	  将old master降为salve，这时再从新master同步数据，这会导致old master中 的大量数据丢失。 
	  关于解决的话，我记得在redis的配置中可以设置：第一可以设置最少的salve 节点个数，比如设置至少要有一个从节点才能同步数据，第二个可以设置主 从数据复制和同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的 数据丢失
	  
### redis为什么这么快

Redis是纯内存操作 执行速度非常快
采用单线程 避免不必要的上下文切换可竞争条件 多线程还要考虑线程安全问题
使用I/O多路复用模型 非阻塞IO

## mysql

### 慢查询

- 如何定位慢查询

  介绍一下当时产生问题的场景 比如：我们当时的一个接口测试的时候非常慢 压测的结果是大概5秒钟
  我们系统中当时采用了运维工具 SkyWalking 可以监测出哪个接口 最终因为是Sql的问题
  在mysql中开启了慢日志查询 设置的值是2秒 一旦sql执行超过两秒就会记录到日志中(调试阶段 生产环境没开启慢日志 影响mysql性能)
  
- 如何分析慢查询SQL

  可以使用MySql自带的分析工具Explain
  通过key和key_len检查是否命中了索引(索引本身存在是否有失效的情况)
  通过type字段查看sql是否有进一步的优化空间 是否存在全索引扫描或者全盘扫描
  通过extra建议判断 是否出现了回表的情况 如果出现了 可以尝试添加索引或修改返回字段来修复
  
- MySql超大分页处理

  在数据量比较大时 limit分页查询 需要对数据进行排序 效率低
  解决方案：覆盖索引+子查询
  
  select *
  from tb_sku t,
  (select id from tb_sku order by id limit 900000,10) a
  where t.id=a.id
  
- 对Sql优化的经验

  表的设计优化  选用合适的字段类型
  索引优化
  SQL语句优化 
  主从复制、读写分离
  分库分表
  SQL语句优化
  select语句必须指明字段名称 避免直接使用select *
  sql语句避免造成索引失效的写法
  尽量用union all代替union union会多进行一次过滤 效率低
  避免在where语句中对字段进行表达式操作
  Join优化 能用inner join就不用left join right join 如果必须使用 一定要以小表驱动。内连接会对两个表进行优化 优先把小表放到外边 大表放到里面 left join 或者right join 不会调整顺序
  
### 索引

索引是帮助mysql高效获取数据的有序数据结构
提高数据检索的效率 降低数据库的IO成本(不需要全表扫描)
通过索引列对数据进行排序 降低数据排序的成本 降低了CPU的消耗

- 索引的底层数据结构

  MySql的InnoDB引擎采用的B+树的数据结构来存储索引
  阶数更多 路径更短
  磁盘读写代价B+树更低 非叶子节点只存储指针 叶子节点存储数据
  B+树便于扫库和区间查询 叶子节点间是一个双向链表
  
- 聚簇索引和非聚簇索引

	- 聚簇索引

	  将数据存储和索引放到了一起 索引结构的叶子保存了完整的行数据
	  特点： 必须有 而且只能有一个
	  
		- 聚簇索引选取规则

		  如果存在主键 主键就是聚簇索引
		  如果不存在主键 将使用第一个唯一UNIQUE索引作为聚簇索引
		  如果表没有主键 或没有合适的唯一索引 则Innodb会生成一个唯一的rowId作为隐藏的聚簇索引
		  
	- 非聚簇索引

	  将数据和索引分开存储 索引结构的叶子节点关联的是对应的主键
	  可以存在多个非聚簇索引
	  
	- 回表查询

	  通过非聚簇索引找到对应的主键值 到聚簇索引中查询出对应的整行数据 这个过程就是回表
	  
- 覆盖索引

  覆盖索引是指查询使用了索引 返回的列 必定在索引中全部能找到
  使用ID查询 直接走聚簇索引查询 一次索引扫描 直接返回全表 性能高
  如果返回的列中 没有创建索引 有可能会触发回表查询 尽量避免使用select *
  
- 索引的创建原则

  先陈述自己在工作中是怎么使用索引的
  主键索引 唯一索引 根据业务创建的索引(复合索引)
  对于数据量较大 且查询比较频繁的表创建索引 单表超过10万数据(增加用户体验)
  针对于常作为查询条件 where，排序 order by，分组 group by操作的字段建立索引
  尽量选择区分度高的列作为索引 尽量建立唯一索引 区分度越高 使用索引的效率越高
  尽量使用联合索引 减少单列索引 查询时 联合索引很多时候可以覆盖索引 节省存储时间 避免回表 提高查询效率
  要控制索引的数量 索引不是多多益善 索引越多 维护索引结构的代价越大 会影响增删改的效率
  如果是字符串类型的字段 字段的长度较长 可以针对于字段的特点 建立前缀索引
  如果索引列不能存储null值 在创建表的时候就使用not null来约束
  
- 索引失效

  使用复合索引时 违反最左前缀原则 
  范围查询右边的列 不能使用索引
  在索引列上进行运算操作
  隐式类型转换
  以%开头的like模糊查询
  
### 事务

- ACID

  原子性 atomicity 事务是不可分割的最小操作单元 要么全部成功 要么全部失败
  一致性 consistency 事务完成时 必须使所有的数据保持一致状态
  隔离性 isolation 数据库系统提供的隔离机制 保证事务在不受外部并发操作影响的独立环境下运行
  持久性 durability 事务一旦提交或回滚 它对数据库中的数据改变就是永久的
  
- 并发事务问题

  脏读：一个事务读到另一个事务还没有提交的数据
  不可重复读：一个事务先后读取同一条记录 但两次读取的数据不同 
  幻读：一个事务按照条件查询数据时 没有对应的数据行 但是在插入数据时 又发现这条数据存在
  通过MySql的隔离级别解决这些问题
  读未提交 
  读已提交 解决脏读
  可重复读 解决脏读 可重复读
  可串行化 全部解决
  
- undo log和redo log

  redo log：记录的是数据页的物理变化 服务宕机可用来同步数据
  undo log：记录的是逻辑日志 当事务回滚时 通过逆操作恢复原来的数据
  redo log保证了事务的持久性 undo log保证了事务的原子性和一致性
  
	- bin log

- mvcc 黑马P32

	- 解释

	  MySql中的多版本并发控制MVCC 指维护一个数据的多个版本 使得读写操作没有冲突
	  隐藏字段
	  trx_id 事务ID 记录每一次操作的事务Id 是自增的
	  roll_pointer 回滚指针 指向上一个版本的事务版本记录地址
	  undo log
	  回滚日志 记录老版本数据
	  版本链 多个事务并行操作某一行数据 记录不同事务修改数据的版本 通过roll_pointer指针形成一个链表
	  readVIew
	  根据readview的匹配规则和当前的一些事务Id判断该访问哪个版本的数据
	  不同的隔离级别快照读是不一样的 最终的访问结果不一样
	  RC 每一次执行快照读是生成readview
	  RR 仅在事务中第一次执行快照读时生成ReadView 后续复用
	  
- 事务的隔离性是如何保证的

  锁：排他锁 如一个事务获取了一个数据行的排他锁 是他事务就不能再获取该行的排他锁
  mvcc：多版本并发控制
  
### 主从同步原理

MySql主从复制的核心就是二进制日志binlog(DDL 数据定义语言)语句和DML(数据操纵语言)语句
主库在事务提交时 会把数据变更记录在二进制日志文件binlog中
从库读取主库的二进制日志文件Binlog 写入到从库的中继日志Relay Log中
从库重做中继日志中的时间 将改变反映他自己的数据

### 分库分表

业务介绍
1 根据自己简历上的项目 想一个较大数据量的业务 请求数过多或业务累计大
2 达到了什么样的量级
具体拆分策略
分库分表中间件 MyCat sharding-sphere
水平分库 将一个库的数据拆分到多个表中 解决海量数据存储和高并发的问题
水平分表 解决单表存储和性能的问题
垂直分库 根据业务进行拆分 高并发下提高磁盘IO和网络连接数
垂直分表 冷热数据分离 多表互不影响

## Spring

### bean

- Spring框架中的单例Bean是线程安全的吗

  不是线程安全的
  Spring框架中有一个@Scope注解 默认的值就是Singleton 单例的
  因为一般在Spring的Bean中注入的都是无状态的对象 没有线程安全问题 如果在Bean中定义了可修改的成员变量 是要考虑线程安全问题的 可以使用多例或者加锁来解决
  
### aop

- 理解

  面向切面编程 用于将那些与业务无关 但却对多个对象产生影响的公共行为和逻辑 抽取公共模块复用 降低耦合
  
  
- 项目中怎么使用

  记录操作日志
  缓存
  Spring实现的事务
  
  怎么使用日志
  核心：使用aop中的环绕通知+切点表达式找到要记录日志的方法 通过环绕通知的参数获取请求方法的参数(类 方法 注解 请求方式等) 获取到这些参数以后 保存到数据库
  
- 事务

  声明式事务：本质是通过AOP功能 对方法前后进行拦截 在执行方法之前开始事务 在执行完目标方法之后根据执行情况提交或者回滚事务
  
	- 事务失效场景

	  1  异常捕获处理 事务通知只有捕捉到了目标抛出的异常 才能进行后续的回滚处理 如果目标自己处理掉异常 事务通知无法知悉 解决方案 在catch中throw 异常
	  2 抛出异常不合规 spring中默认只会回滚非检查异常  rollback = Exception.class
	  3 方法不是public的 在spring中，有两种动态代理的方式，一种是jdk，它是将原始对象放入代理对象内部，通过调用内含的原始对象来实现原始的业务逻辑，这是一种装饰器模式；而另一种是cglib，它是通过生成原始对象的子类，子类复写父类的方法，从而实现对父类的增强。
	  jdk中，如果是private的方法，显然是无法访问的，而在cglib中，也是同样，private方法也无法访问
	  4 业务和spring事务代码必须在一个线程中  spring事务实现中使用了ThreadLocal，ThreadLocal大家应该知道吧，可以实现同一个线程中数据共享，必须是同一个线程的时候，数据才可以共享，这就要求业务代码必须和spring事务的源码执行过程必须在一个线程中，才会受spring事务的控制
	  5 自身调用问题 spring是通过aop的方式，对需要spring管理事务的bean生成了代理对象，然后通过代理对象拦截了目标方法的执行，在方法前后添加了事务的功能，所以必须通过代理对象调用目标方法的时候，事务才会起效
	  
	  
	- 事务传播机制

## SpringBoot

### SpringBoot自动配置原理

通过@SpringBootConfiguration引入了@EnableAutoConfiguration(负责启动自动配置功能)
@EnableAutoConfiguration引入了@Import注解
Spring容器启动时 加载IOC容器时 会解析@Import注解
@Import注解导入了AutoConfigurationImportSelector继承deferedImportSelector(这个会使SpringBoot的自动配置类的加载顺序放在最后 便于自定义扩展和覆盖)
然后读取出META-INF/Spring.factories文件
过滤出所有的AutoConfigurationClass类型的类
最后通过@Condition排除出无效的配置类

## kafka

### kafka是如何保证消息不丢失的

生产者发送消息到Broker丢失
设置异步发送 发送失败使用回调进行记录或重发
失败重试 参数配置 可以设置重试次数
消息在broker中丢失
发送确认acks配置 改成all 让所有的副本都参与保存数据后确认
消费者从Broker中接收消息丢失
关闭自动提交偏移量 开始手动提交偏移量
提交方式 改成同步+异步提交

### kafka重复消费消息怎么解决

关闭自动提交偏移量 使用手动提交
提交方式 最好是同步+异步提交
幂等方案

### kafka怎么保证消费的顺序性

问题原因：
一个topic的数据可能存储在不同的分区中 每个分区都有一个按照顺序消费的偏移量 如果消费者关联了多个分区不能保证顺序性
解决方案
发送消息指定分区号
发送消息时按照相同的业务设置相同的key
阻塞队列

### kafka的高可用机制有了解过吗

主要有两个方面 一个是集群 一个是复制机制

集群
一个kafka集群由多个broker实例组成 即使某一台宕机 也不耽误其他broker继续对外提供服务
复制机制
一个topic有多个分区 每个分区有多个副本 有一个leader 其他是follower 副本存储在不同的broker中
所有的分区副本的内容都是相同的 如果leader发生故障时 会自动将其中一个follower提升为leader 保证了系统的容错性和可用性

### 解释下kafka复制机制中ISR

ISR (in-sync replica) 需要同步复制的follower
分区副本分成了两类 一个是ISR 与leader副本同步保存数据 另外一个普通的副本 是异步同步数据 当leader挂掉之后 会优先从ISR列表中选取一个作为新的leader

### kafka的数据清理机制

kafka存储结构
kafka中topic数据存储在分区上 分区如果文件过大就会分段存储segment
每个分段都在磁盘上以索引(xxx.index)和日志文件(xxx.log)的形式存储
分段的好处是 第一能够减少耽搁文件内容的大小 查找数据方便 第二方便kafka进行日志清理
kafka的日志清理策略有两个
根据消息的保留时间 当消息在kafka中保存的时间超过了指定的时间 就会触发清理过程 默认是168小时
根据topi存储的数据大小 当topic所占的日志文件大小大于一定的阈值时 则开始删除最久的消息。这个配置需要手动开启

### kafka中实现高性能的设计有了解过吗

消息分区：不受单台服务器限制 可以不受限的处理更多的数据
顺序读写：磁盘顺序读写 提升读写效率
页缓存：把磁盘中的数据缓存到内存中 把对磁盘的访问变为对内存的访问
零拷贝：减少上下文切换及数据拷贝
消息压缩：减少磁盘IO和网络IO
分批发送：将消息打包批量发送 减少网络开销

- 零拷贝

